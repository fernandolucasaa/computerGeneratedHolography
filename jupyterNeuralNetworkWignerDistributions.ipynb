{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning study on the results of the 1D Pseudo-Wigner Distribution using Neural Networks\n",
    "\n",
    "**Why?**\n",
    "\n",
    "Check if the wigner distribution of an hologram is capable to predict how many point sources generated the hologram (1 to 5 sources).\n",
    "\n",
    "**How?**\n",
    "\n",
    "Using a convolutional neural networks to solve this classification problem.\n",
    "\n",
    "**What?**\n",
    "\n",
    "Using the keras libray (python).\n",
    "\n",
    "**Some examples:**\n",
    "* https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 8, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "path = 'output/wigner_distribution/'\n",
    "file_name = 'wd_results.npy'\n",
    "\n",
    "dataset = np.load(path + file_name)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN (Convolutional Neural Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_targets_array(nb_class, X_train):\n",
    "    \"\"\"\n",
    "    Compute an array with the targets of the dataset. Note that the number on the array correspond to the number of \n",
    "    sources minus one\n",
    "    \"\"\"\n",
    "    # Number of the examples\n",
    "    nb_holograms = X_train.shape[0]\n",
    "    \n",
    "    # Number of examples per class\n",
    "    nb_holograms_class = int(nb_holograms / nb_class)\n",
    "    \n",
    "    # Y vector\n",
    "    Y_array = np.zeros((nb_holograms,))\n",
    "    counter = 1\n",
    "    target = 0\n",
    "    \n",
    "    for i in range(nb_holograms):\n",
    "        if counter == (nb_holograms_class + 1):\n",
    "            target = target + 1\n",
    "            counter = 1\n",
    "        Y_array[i,] = target\n",
    "        counter = counter + 1    \n",
    "    \n",
    "    return Y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 200, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "# Select one of the 8 frequencies ! BUG, MUST FIX\n",
    "X_train = dataset[:,0,:,:]\n",
    "\n",
    "# The 1 signify that the images are greyscale\n",
    "X_train = X_train.reshape(125,200,200,1)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125,)\n",
      "(125, 5)\n"
     ]
    }
   ],
   "source": [
    "# Compute array of targets\n",
    "nb_class = 5\n",
    "Y_array = compute_targets_array(nb_class, X_train)\n",
    "\n",
    "print(Y_array.shape)\n",
    "\n",
    "# One-hot encode target column\n",
    "Y_train = to_categorical(Y_array)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Sequential() # allows build a model layer by layer\n",
    "\n",
    "# Add model layers\n",
    "\n",
    "# Conv2D layer: \n",
    "# 64 nodes, 3x3 filter matrix, Rectified Linear Activation as activation function,\n",
    "# shape of each input (200, 200, 1,) with 1 signifying images are greyscale\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(200,200,1))) \n",
    "\n",
    "# 32 nodes\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "\n",
    "# Flatten layer: connection between the convolution and dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layer: used for the output layer\n",
    "# 5 nodes for the output layer, one for each possible outcome (1-5)\n",
    "# 'softmax' as activation function, it makes the output sump up to 1 so the output\n",
    "# can be interpreted as probalities\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three parameters:\n",
    "# optmizer: 'adam'\n",
    "# loss function: 'categorical_crossentropy', the most common choice for classification\n",
    "# metrics: 'accuracy', to see the accuracy score\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125 samples, validate on 125 samples\n",
      "Epoch 1/2\n",
      "125/125 [==============================] - 27s 212ms/step - loss: 1566685.0600 - accuracy: 0.1760 - val_loss: 2101887.7750 - val_accuracy: 0.2000\n",
      "Epoch 2/2\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 1084067.4833 - accuracy: 0.2000 - val_loss: 126335.1262 - val_accuracy: 0.2160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x201c1c664c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of epochs: number of tmes the model wil cycle trough the data\n",
    "model.fit(X_train, Y_train, validation_data=(X_train, Y_train), epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evalutation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 21.60%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print('Accuracy: %.2f%%' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 4 (expected: 0)\n",
      "Predicted: 4 (expected: 0)\n",
      "Predicted: 4 (expected: 0)\n",
      "Predicted: 4 (expected: 0)\n",
      "Predicted: 4 (expected: 0)\n"
     ]
    }
   ],
   "source": [
    "# Make probability predictions with the model\n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "# Round predictions \n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "\n",
    "# Make class predictions with the model\n",
    "predictions = model.predict_classes(X_train)\n",
    "\n",
    "# Summarize the first 5 cases\n",
    "for i in range(5):\n",
    "    print('Predicted: %d (expected: %d)' % (predictions[i], Y_array[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save weights and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model structure and weights\n"
     ]
    }
   ],
   "source": [
    "# Serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"output/neural_networks/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# Serialize weights to HDF5\n",
    "model.save_weights(\"output/neural_networks/model.h5\")\n",
    "print(\"Saved model structure and weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 21.60%\n"
     ]
    }
   ],
   "source": [
    "# The model weights and architecture were saved separated, so it must re-compile\n",
    "\n",
    "# Load json and create model\n",
    "json_file = open('output/neural_networks/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights into new model\n",
    "loaded_model.load_weights(\"output/neural_networks/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# Evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_train, Y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 198, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 196, 196, 32)      18464     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1229312)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 6146565   \n",
      "=================================================================\n",
      "Total params: 6,165,669\n",
      "Trainable params: 6,165,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error, BUG, MUST FIX\n",
    "\n",
    "# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
