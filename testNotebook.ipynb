{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import wignerDistribution as wd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the 1D PWD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dictionaries** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMatFile(file_path, file_name, key):\n",
    "    \"\"\"\n",
    "    Load a mat file and return an item of the dictionary loaded.\n",
    "    \"\"\"    \n",
    "    # read mat file dictionary\n",
    "    dictionary = scipy.io.loadmat(file_path + file_name)\n",
    "    \n",
    "    # access item of a dictionary\n",
    "    array = dictionary[key]\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder's path\n",
    "path = 'C:\\\\Users\\\\ferna\\\\Desktop\\\\computerGeneratedHolography'\n",
    "\n",
    "# Load hologram dataset\n",
    "file_path = path + '\\\\output\\\\dataset\\\\'\n",
    "file_name = 'hDataset.mat'\n",
    "key = 'hDataset'\n",
    "hologram_dataset = loadMatFile(file_path, file_name, key)\n",
    "\n",
    "# Load reconstructed images dataset\n",
    "file_name = 'rDataset.mat'\n",
    "key = 'rDataset'\n",
    "reconstruction_dataset = loadMatFile(file_path, file_name, key)\n",
    "\n",
    "# Load 3D points dataset\n",
    "file_name = 'pDataset.mat'\n",
    "key = 'pDataset'\n",
    "points_dataset = loadMatFile(file_path, file_name, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200, 25)\n",
      "(200, 200, 25)\n",
      "(75, 3)\n"
     ]
    }
   ],
   "source": [
    "print(hologram_dataset.shape)\n",
    "print(reconstruction_dataset.shape)\n",
    "print(points_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute 1D Pseudo-Wigner Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_1D_wigner_distribution(dataset, n, seq_legth, angle):\n",
    "    \"\"\"\n",
    "    Calculates the  1D pseudo-Wigner distribution of the n first images (in gray levels) in the dataset. seq_length is the \n",
    "    length in pixels of the operating window and it has to be an odd number (9 is a common operative value). \n",
    "    The angle variable in degrees determines the spatial orientation of the distribution.\n",
    "    \"\"\"\n",
    "    wd_results = []\n",
    "    for i in range(n):\n",
    "        test_image = dataset[:,:,i]\n",
    "        wd_results.append(wd.wigner_distribution(test_image, seq_legth, angle))\n",
    "    return wd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "calculating ...\n",
      "calculating in row  100  ...\n",
      "calculating in row  200  ...\n",
      "Wall time: 4min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = hologram_dataset\n",
    "n = hologram_dataset.shape[2]\n",
    "seq_legth = 9 # length in pixels of the operating window\n",
    "angle = 0     # spatial orientation of the distribution (degrees)\n",
    "\n",
    "wd_results = calculate_1D_wigner_distribution(dataset, n, seq_legth, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to .npy file\n",
    "np.save('wd_results', wd_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 8, 200, 200)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .npy file\n",
    "wd_results_array = np.load('wd_results.npy')\n",
    "wd_results_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute database to Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions to be used in the features' computation**\n",
    "\n",
    "The functions below compute the sobel of an image and the count the number of pixels in the x and y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel(image):\n",
    "    w = len(image)\n",
    "    kernel_x = np.array([ [ 1, 0,-1],\n",
    "                          [ 2, 0,-2],\n",
    "                          [ 1, 0,-1] ])\n",
    "\n",
    "    kernel_y = np.array([ [ 1, 2, 1],\n",
    "                          [ 0, 0, 0],\n",
    "                          [-1,-2,-1] ])\n",
    "    \n",
    "    grad_x = np.zeros([w - 2, w - 2])\n",
    "    grad_y = np.zeros([w - 2, w - 2])\n",
    "    \n",
    "    for i in range(w - 2):\n",
    "        for j in range(w - 2):\n",
    "            grad_x[i, j] = sum(sum(image[i : i + 3, j : j + 3] * kernel_x))\n",
    "            grad_y[i, j] = sum(sum(image[i : i + 3, j : j + 3] * kernel_y))\n",
    "            if grad_x[i, j] == 0:\n",
    "                grad_x[i, j] = 0.000001 \n",
    "    \n",
    "    mag = np.sqrt(grad_y ** 2 + grad_x ** 2)\n",
    "    ang = np.arctan(grad_y / (grad_x + np.finfo(float).eps))\n",
    "  \n",
    "    # Gradient computation\n",
    "    return [mag,ang]\n",
    "\n",
    "def pixel_count(image):\n",
    "    pc_x = np.zeros(len(image))\n",
    "    pc_y = np.zeros(len(image))\n",
    "  \n",
    "    # Pixel count computation\n",
    "    for i in range(len(image)):\n",
    "        pc_x[i] = np.count_nonzero(image[i, :])\n",
    "        pc_y[i] = np.count_nonzero(image[:, i])\n",
    "\n",
    "    return [pc_x, pc_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class for the set of images generated by the Wigner Distribution of an image**\n",
    "\n",
    "The 1D PWD (Pseudo-Wigner Distribution) generates 8 imagens from one image as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Element:\n",
    "    def __init__(self, data, target):\n",
    "        self.target = target\n",
    "        self.features = {'var' : 0,\n",
    "                         'std' : 0,\n",
    "                         'mean_grad_M' : 0,\n",
    "                         'std_grad_M'  : 0,\n",
    "                         'mean_grad_D' : 0,\n",
    "                         'std_grad_D'  : 0,\n",
    "                         'mean_PC_X'   : 0,\n",
    "                         'std_PC_X'    : 0,\n",
    "                         'active_PC_X' : 0,\n",
    "                         'mean_PC_Y'   : 0,\n",
    "                         'std_PC_Y'    : 0,\n",
    "                         'active_PC_Y' : 0}\n",
    "        self.computeFeatures(data)\n",
    "        \n",
    "    def computeFeatures(self, data):\n",
    "        \"\"\"\n",
    "        Compute the 12 features of each image (8 images in total) and returns the average of each feature.\n",
    "        \"\"\"\n",
    "        # Auxiliar variable\n",
    "        matrix = np.zeros((8,12))\n",
    "        pos = 0 # 0..7\n",
    "        \n",
    "        # Feature computation for each image\n",
    "        for image in data:\n",
    "            # Feature computation\n",
    "            mag, ang = sobel(image)\n",
    "            pcx, pcy = pixel_count(image)\n",
    "            matrix[pos][0] = (np.var(image))\n",
    "            matrix[pos][1] = (np.std(image))\n",
    "            matrix[pos][2] = (np.mean(mag))\n",
    "            matrix[pos][3] = (np.std(mag))\n",
    "            matrix[pos][4] = (np.mean(ang))\n",
    "            matrix[pos][5] = (np.std(ang))\n",
    "            matrix[pos][6] = (np.mean(pcx))\n",
    "            matrix[pos][7] = (np.std(pcx))\n",
    "            matrix[pos][8] = (np.count_nonzero(pcx))\n",
    "            matrix[pos][9] = (np.mean(pcy))\n",
    "            matrix[pos][10] = (np.std(pcy))\n",
    "            matrix[pos][11] = (np.count_nonzero(pcy)) \n",
    "            # Update variable\n",
    "            pos = pos + 1\n",
    "        \n",
    "        # Features' average\n",
    "        keys = ['var', 'std', 'mean_grad_M', 'std_grad_M', 'mean_grad_D', 'std_grad_D', 'mean_PC_X', 'std_PC_X', 'active_PC_X', 'mean_PC_Y', 'std_PC_Y', 'active_PC_Y']\n",
    "        for i in range(12):\n",
    "            self.features[keys[i]] = sum(matrix[:,i]/8)\n",
    "    \n",
    "    def __print__(self):\n",
    "        print(\"Element target: \" + str(self.target))\n",
    "        print(\"Element features:\")\n",
    "        print(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 200, 200)\n",
      "Element target: 1\n",
      "Element features:\n",
      "{'var': 9024828.034729265, 'std': 2430.215837108408, 'mean_grad_M': 10334.639101530625, 'std_grad_M': 6843.350135753646, 'mean_grad_D': 0.02804709551718424, 'std_grad_D': 0.8803386817979355, 'mean_PC_X': 200.0, 'std_PC_X': 0.0, 'active_PC_X': 200.0, 'mean_PC_Y': 200.0, 'std_PC_Y': 0.0, 'active_PC_Y': 200.0}\n"
     ]
    }
   ],
   "source": [
    "'''array = wd_results_array[2]\n",
    "print(array.shape)\n",
    "\n",
    "elem = Element(array, 1)\n",
    "elem.__print__()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class for create a dataset with all images computed by Octave's code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, array, length, y_list):\n",
    "        self.array = array   # (nb_examples, 8, 200, 200)\n",
    "        self.length = length # nb_examples\n",
    "        self.wd_list = []\n",
    "        self.wd_list = self.createElements(y_list)\n",
    "        self.features = [[float(f) for f in elem.features.values()] for elem in self.wd_list]\n",
    "        self.raw_targets  = [[self.wd_list[i].target] for i in range(self.length)]\n",
    "    \n",
    "    def createElements(self, y_list):\n",
    "        elements = []\n",
    "        pos = 0\n",
    "        for row in self.array:\n",
    "            # row : (8, 200, 200)\n",
    "            elements.append(Element(row, y_list[pos]))\n",
    "            pos = pos + 1\n",
    "        return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTargets(array):\n",
    "    targets = []\n",
    "    y = 1\n",
    "    for i in range(len(array)):\n",
    "        targets.append(y)\n",
    "        if((i+1)%5 == 0):\n",
    "            y = y + 1\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 8, 200, 200)\n",
      "Element target: 1\n",
      "Element features:\n",
      "{'var': 10218840.74310089, 'std': 2753.179664325147, 'mean_grad_M': 9800.17669808202, 'std_grad_M': 6686.825004976745, 'mean_grad_D': 0.4245315875688738, 'std_grad_D': 0.6320330591719492, 'mean_PC_X': 200.0, 'std_PC_X': 0.0, 'active_PC_X': 200.0, 'mean_PC_Y': 200.0, 'std_PC_Y': 0.0, 'active_PC_Y': 200.0}\n",
      "Element target: 1\n",
      "Element features:\n",
      "{'var': 9828456.360765265, 'std': 2491.277620935381, 'mean_grad_M': 9278.490214573858, 'std_grad_M': 6634.414920994312, 'mean_grad_D': 0.0045929823100968005, 'std_grad_D': 0.8127970953675628, 'mean_PC_X': 200.0, 'std_PC_X': 0.0, 'active_PC_X': 200.0, 'mean_PC_Y': 200.0, 'std_PC_Y': 0.0, 'active_PC_Y': 200.0}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "array = wd_results_array[0:2, :, :, :]\n",
    "target_list = computeTargets(wd_results)\n",
    "\n",
    "test = Dataset(array, len(array), target_list)\n",
    "print(test.array.shape)\n",
    "test.wd_list[0].__print__()\n",
    "test.wd_list[1].__print__()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(array):\n",
    "    \"\"\"\n",
    "    bla bla bla\n",
    "    \"\"\"\n",
    "    target_list = computeTargets(array)\n",
    "    dataset = Dataset(array, len(array), target_list)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def cvt_obj_nparray(dataset):\n",
    "    X = np.zeros((dataset.length, 12))\n",
    "    Y = np.zeros((dataset.length,))\n",
    "    for i, elem in enumerate(dataset.wd_list):\n",
    "        Y[i] = elem.target\n",
    "        for j, feature in enumerate(elem.features):\n",
    "            X[i, j] = elem.features[feature]\n",
    "    return X, Y\n",
    "\n",
    "def create_data_file(filename):\n",
    "    # Load the database (.npy) files \n",
    "    wd_results_array = np.load(filename) \n",
    "\n",
    "    print(\"Creating dataset...\")\n",
    "    data_set = generate_dataset(wd_results_array)\n",
    "    print (\"\\nFinished creating dataset\\n\")\n",
    "\n",
    "    X_array, Y_array = cvt_obj_nparray(data_set)\n",
    "\n",
    "    return X_array, Y_array\n",
    "\n",
    "#Function that normalize the features\n",
    "def normalize(arr):\n",
    "    max_line = np.max(arr, axis=0)\n",
    "    min_line = np.min(arr, axis=0)\n",
    "    \n",
    "    arr = (arr - min_line) / (max_line - min_line)\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "array = wd_results_array[0:5, :, :, :]\n",
    "dataset = generate_dataset(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "\n",
      "Finished creating dataset\n",
      "\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_array, Y_array = create_data_file('wd_results.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 12)\n",
      "(25,)\n"
     ]
    }
   ],
   "source": [
    "print(X_array.shape)\n",
    "print(Y_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
